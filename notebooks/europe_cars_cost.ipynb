{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6afe3a5-a367-4e9c-a561-5e8b0f8223f6",
   "metadata": {},
   "source": [
    "## Создание приложения для предсказания стоимости европейского автомобиля по VIN-коду"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4514670-23e6-4cec-a6d2-5902b4d57455",
   "metadata": {},
   "source": [
    "### 1. Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113cf19-de82-430e-bbad-70caf072dbf4",
   "metadata": {},
   "source": [
    "Нам предосталлен текстовый файл с собранными данными о vin-кодах различных стран и производителей. В тексте vin и стоимость расположены с учетом паттерна \"\\n[VIN:цена]\\n\". Наша задача, имея только эту информацию, разделить, с помощью регулярных выражений, вин код на части, а затем, обучив модель машинного обучения создать пользовательское приложение. Так как для разных стран производителей существуют разные правила формирования VIN, мы ограничимся только Европой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "f706e345-76ee-42a3-adfa-87ddb5861e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from flask import Flask, request, render_template_string\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3d247-0284-45fb-9c75-fc251bfce98f",
   "metadata": {},
   "source": [
    "### 2. Подключение к данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "321cf464-90a2-446e-a72a-e6f450768f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'all_models_train.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c1c66-1a19-47ab-b678-0eaffe70501d",
   "metadata": {},
   "source": [
    "Валидность vin будем проверять по наличию запрещенных символов I, O и Q, длине в 7мь знаков, а также наличию цифр в конце кода. Проверку сразу включим в парсинг имеющихся данных и разобьем на именованные группы для удобного создания датафрейма. Также, в проверку включим ограничение стран Европы, которые указываются в первой части кода STUVWXYZ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17896b-9a78-4b48-824a-adca407bfb63",
   "metadata": {},
   "source": [
    "### 3. Создание датасета и преддобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "dc0f9f12-6b27-43a0-8d4d-b375b40ecdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'''\n",
    "    (?P<country>[STUVWXYZ1-9])\n",
    "    (?P<manufacturer>[A-HJ-NPR-Z])\n",
    "    (?P<vehicle>[A-HJ-NPR-Z0-9]{5})\n",
    "    (?P<check_digit>[0-9X])\n",
    "    (?P<year>[A-HJ-NPR-Z0-9])\n",
    "    (?P<plant_code>[A-HJ-NPR-Z0-9])\n",
    "    (?P<serial_number>[A-HJ-NPR-Z0-9]{6})\n",
    "    :(?P<price>\\d+)\n",
    "''', re.X)\n",
    "\n",
    "\n",
    "df = pd.DataFrame([x.groupdict() for x in regex.finditer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "6ac6b994-6d3b-4663-92d1-643f26cdf007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>check_digit</th>\n",
       "      <th>year</th>\n",
       "      <th>plant_code</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>BV541</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>X</td>\n",
       "      <td>019560</td>\n",
       "      <td>17250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V</td>\n",
       "      <td>W</td>\n",
       "      <td>EK73C</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>P</td>\n",
       "      <td>046847</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z</td>\n",
       "      <td>V</td>\n",
       "      <td>BP8EM</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "      <td>237253</td>\n",
       "      <td>11600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>GM4A7</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>346791</td>\n",
       "      <td>15400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>CK262</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>010506</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country manufacturer vehicle check_digit year plant_code serial_number  \\\n",
       "0       T            F   BV541           5    7          X        019560   \n",
       "1       V            W   EK73C           2    6          P        046847   \n",
       "2       Z            V   BP8EM           0    D          5        237253   \n",
       "3       X            X   GM4A7           4    E          G        346791   \n",
       "4       T            H   CK262           2    7          2        010506   \n",
       "\n",
       "   price  \n",
       "0  17250  \n",
       "1   4000  \n",
       "2  11600  \n",
       "3  15400  \n",
       "4   9000  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "4edd3da0-426e-4e84-b508-e985c60bf803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country          object\n",
       "manufacturer     object\n",
       "vehicle          object\n",
       "check_digit      object\n",
       "year             object\n",
       "plant_code       object\n",
       "serial_number    object\n",
       "price            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "e64cf222-52d9-414a-a35c-b625ff58f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "439c03f7-a804-465b-85dc-172c691cdbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country          0\n",
       "manufacturer     0\n",
       "vehicle          0\n",
       "check_digit      0\n",
       "year             0\n",
       "plant_code       0\n",
       "serial_number    0\n",
       "price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9b09b752-065b-4a9a-8d81-c70595933be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fa40e84b-a43a-4c8a-9b0c-5c5d9a7fcc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48226, 8)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a3838-942f-47c0-ba70-915cb21f7c70",
   "metadata": {},
   "source": [
    "Получили датафрейм с кодом страны, производителя, атрибутами двигателя, проверочной цыфрой, годом производства, кодом завода, серийным номером и соответсвующей ценой. Пропусков нет, дубликатов тоже. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5046c4-3dd3-449b-8dc3-13d54758f254",
   "metadata": {},
   "source": [
    "### 4. Подготовка данных к моделированию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206537c-4743-4394-8091-6b427f01e2ef",
   "metadata": {},
   "source": [
    "Категориальные признаки закодируем с помощью label_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "8eff6f18-efc6-4009-b80f-7fdda48030f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoders = {}\n",
    "column_cat = ['country', 'manufacturer', 'vehicle', 'check_digit', 'year', 'plant_code', 'serial_number']\n",
    "\n",
    "for column in column_cat:\n",
    "    ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    df[column] = ordinal_encoder.fit_transform(df[[column]])\n",
    "    ordinal_encoders[column] = ordinal_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bce875-6232-4204-bdd8-cf5fd55000c4",
   "metadata": {},
   "source": [
    "Создадим валидационные и тестовые выборки для чистого эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "794eb4a2-3784-43ff-8779-191fed8936b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "\n",
    "X_train, X_test_valid, y_train, y_test_valid = train_test_split(X, y, test_size=0.3, random_state=33)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, test_size=0.5, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f37b79-b4a5-4777-ac77-70481a343f92",
   "metadata": {},
   "source": [
    "значения сильно разбросаны по значениям - скалируем параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "4a5c2e67-2303-4aa5-a99e-2dd3f4e1b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc090da-0b4b-491a-bb23-080452355ae7",
   "metadata": {},
   "source": [
    "### 5. Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a97f2-97b8-46e3-a21f-3a004808233c",
   "metadata": {},
   "source": [
    "У нас большая часть данных это категории переведенные в код - лучше всего должен справиться решающий лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "8dd27a69-97f3-475a-aa32-6be03a928fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2577.468970865716\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=33)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_valid)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b1f27479-78ea-4f70-b15d-bf56f13e535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 33758, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 14536.378518\n",
      "Root Mean Squared Error: 2824.7145561138937\n"
     ]
    }
   ],
   "source": [
    "l_model = LGBMRegressor(num_leaves=31, learning_rate=0.05, n_estimators=100)\n",
    "\n",
    "l_model.fit(X_train, y_train, categorical_feature=all)\n",
    "\n",
    "\n",
    "y_pred = l_model.predict(X_valid)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a4ff7-7d31-4049-9203-757e15404a2c",
   "metadata": {},
   "source": [
    "### 6. Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ea43e-823b-418e-a700-018ef87e2b27",
   "metadata": {},
   "source": [
    "Попробуем улучшить подбором параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "132d5aa2-cd5f-43f7-afa8-f004b8bbb36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  29.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  28.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  28.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  24.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  24.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  23.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  16.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  16.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  16.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  21.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  22.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  22.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  37.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  37.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  37.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  22.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  23.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  22.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   9.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   8.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   8.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  38.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  38.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  36.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  12.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=15, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=15, n_estimators=200; total time=  11.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=15, n_estimators=200; total time=  11.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=6, min_samples_split=10, n_estimators=300; total time=  16.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=6, min_samples_split=10, n_estimators=300; total time=  17.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=6, min_samples_split=10, n_estimators=300; total time=  17.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  13.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  12.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  13.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  18.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  17.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=15, n_estimators=400; total time=  24.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=15, n_estimators=400; total time=  24.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=15, n_estimators=400; total time=  24.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=15, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=15, n_estimators=200; total time=  11.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=15, n_estimators=200; total time=  11.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=6, min_samples_split=10, n_estimators=200; total time=  11.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=6, min_samples_split=10, n_estimators=200; total time=  11.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=6, min_samples_split=10, n_estimators=200; total time=  11.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=6, min_samples_split=5, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=6, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=6, min_samples_split=5, n_estimators=100; total time=   5.5s\n",
      "Root Mean Squared Error: 2484.847820353148\n",
      "Best Parameters: {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=20, cv=3, scoring='neg_mean_squared_error',\n",
    "    verbose=2, random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Оценка лучшей модели\n",
    "y_pred = best_rf_model.predict(X_valid)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fd882-083c-40f1-b7b1-9b1ec64b4888",
   "metadata": {},
   "source": [
    "Ошибка достаточно высокая, но для примерной оценки можем использовать в качестве отправной точки. В финальных выводах сформируем рекомендации по улучшению модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c06606-fa7c-4903-98e0-b5f7811d82d6",
   "metadata": {},
   "source": [
    "### 7. Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "d317dc7e-4e74-4c8e-b4f9-760be53c568f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2476.3229950377536"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_rf_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1116b-6ed1-49dc-906b-712d7dc8c467",
   "metadata": {},
   "source": [
    "При тестировании качество упало незначительно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef23a6-b1d1-44aa-a2f8-1e2e77c6f281",
   "metadata": {},
   "source": [
    "### 8. Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "7cb3de64-1dcb-4a29-bee4-8721caf618db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error of baseline model: 9512.802640673668\n"
     ]
    }
   ],
   "source": [
    "dummy_regressor = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "y_pred = dummy_regressor.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error of baseline model: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf86bdb-8b1a-4ac5-bb52-788976f57ebe",
   "metadata": {},
   "source": [
    "Все же наша модель луче чем простое среднее - использование модели считаем оправданным. Запакуем модель\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0a4d2-639c-4e5a-824b-80cd5065b2aa",
   "metadata": {},
   "source": [
    "### 9.Запаковка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "762ac045-e28c-4778-8394-688231579b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74dce6-d904-4fbc-8338-4ddf25c73100",
   "metadata": {},
   "source": [
    "### 10. Создание приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a58230-e007-4fdb-a8dd-eadaaca35160",
   "metadata": {},
   "source": [
    "Для начала соберем части входного вин-кода и закодируем полученную сточку для передачи в модель, а также проведем скалирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "564585ec-abbf-4563-a35d-47b63879f0d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "HTML_TEMPLATE = '''\n",
    "<!doctype html>\n",
    "<html>\n",
    "<head><title>VIN Price Predictor</title></head>\n",
    "<body>\n",
    "    <h1>VIN Price Prediction</h1>\n",
    "    <form action=\"/\" method=\"post\">\n",
    "        <label for=\"vin\">Enter VIN:</label>\n",
    "        <input type=\"text\" id=\"vin\" name=\"vin\" required>\n",
    "        <button type=\"submit\">Predict</button>\n",
    "    </form>\n",
    "    {% if prediction %}\n",
    "        <h2>Predicted Price: {{ prediction }}</h2>\n",
    "    {% endif %}\n",
    "    {% if error %}\n",
    "        <h2 style=\"color: red;\">{{ error }}</h2>\n",
    "    {% endif %}\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def predict():\n",
    "    with open('encoder.pkl', 'rb') as file:\n",
    "        encoder = pickle.load(file)\n",
    "\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "        best_rf_model = pickle.load(file)\n",
    "    \n",
    "    \n",
    "    prediction = None\n",
    "    error = None\n",
    "    if request.method == 'POST':\n",
    "        vin = request.form['vin']\n",
    " \n",
    "        if not re.fullmatch(r'[A-HJ-NPR-Z0-9]{17}', vin):\n",
    "            error = 'Invalid VIN. Please enter a valid 17-character VIN (excluding I, O, Q).'\n",
    "\n",
    "        elif not re.match(r'[S-ZV-X][A-HJ-NPR-Z0-9]{16}', vin):\n",
    "            error = 'Valid VIN but not from Europe. Please enter a European VIN.'\n",
    "        else:\n",
    "            column_cat = ['country', 'manufacturer', 'vehicle', 'check_digit', 'year', 'plant_code', 'serial_number']\n",
    "            regex_v = re.compile(r'''\n",
    "                (?P<country>[STUVWXYZ1-9])\n",
    "                (?P<manufacturer>[A-HJ-NPR-Z])\n",
    "                (?P<vehicle>[A-HJ-NPR-Z0-9]{5})\n",
    "                (?P<check_digit>[0-9X])\n",
    "                (?P<year>[A-HJ-NPR-Z0-9])\n",
    "                (?P<plant_code>[A-HJ-NPR-Z0-9])\n",
    "                (?P<serial_number>[A-HJ-NPR-Z0-9]{6})\n",
    "            ''', re.X)\n",
    "            value_vin = pd.DataFrame([x.groupdict() for x in regex_v.finditer(vin)])\n",
    "            prediction = value_vin\n",
    "            encoded_values = []\n",
    "            for column, encoder in ordinal_encoders.items():\n",
    "                encoded_value = encoder.transform([[value_vin.iloc[0][column_cat.index(column)]]])\n",
    "                encoded_values.append(encoded_value[0])\n",
    "                \n",
    "            encoded_values_stacked = np.hstack(encoded_values)\n",
    "            final_predict = best_rf_model.predict(encoded_values_stacked.reshape(1, -1))\n",
    "            prediction = final_predict\n",
    "\n",
    "    return render_template_string(HTML_TEMPLATE, prediction=prediction, error=error)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1f25a-8060-4533-a079-a8810d1354e0",
   "metadata": {},
   "source": [
    "Здесь пока до ума не довел. Есть отработка интерфейса, исключений, проверка валидности, но модель внутри не работает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cba13c-23d2-4429-81a5-10cdefc5b65c",
   "metadata": {},
   "source": [
    "### 11. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42652b0-21ee-4908-a129-6e5fe4c3dc7d",
   "metadata": {},
   "source": [
    "В рамках работы удалось собрать датасет из простых текстовых данных о вин-кодах со стоимостями. Удалось построить модель машинного обучения. Модель требует доработки - стоит рассмотреть другие регрессоры и поработать с моделями, которые лучше работают с категориальными признаками, добавив перебор гиперпараметров. Также, сократить ошибку поможет включение более глубокого парсинга сегментов vin, например мощности двигателя итд. Приложение также требует доработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1ce6b-5390-430c-bea5-a2a3f9c1562d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
